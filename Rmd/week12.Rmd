---
title: "week12.Rmd"
author: "Joy Zhou"
date: "2023-04-14"
output: html_document
---

### Script Settings and Resources
```{r, message=F}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(RedditExtractoR)
library(tidyverse)
library(rvest)
library(tm)
library(qdap)
library(textstem)
library(RWeka)
library(ldatuning)
library(parallel)
library(doParallel)
library(topicmodels)
library(tidytext)
library(wordcloud)
library(stats)
```

### Data Import and Cleaning
```{r}
#io_psych_url <- find_thread_urls(
  #subreddit = "IOPsychology",
  #period = "year",
  #sort_by = "new"
#)

#io_psych_content <- get_thread_content(io_psych_url$url)

#title <- io_psych_content$threads$title
#upvotes <- io_psych_content$threads$upvotes

#week12_tbl <- tibble(title, upvotes)

#write.csv(week12_tbl, "../data/week12_tbl.csv", row.names = F)

week12_tbl <- read.csv("../data/week12_tbl.csv")

io_corpus_original <- VCorpus(VectorSource(week12_tbl[,1]))

io_stem <- c("io", "i/o")
psych_stem <- c("psychology", "psychologist", "psychologists", "psych")
##to_lower needs to be after contraction as the latter capitalizes the first letter in a sentence
io_corpus <- io_corpus_original %>%
  tm_map(content_transformer(str_replace_all), pattern = "’", replacement = "'") %>%
  tm_map(content_transformer(str_replace_all), pattern = "-|/", replacement = " ") %>%
  tm_map(content_transformer(str_remove), pattern = "‘|“|”") %>%
  tm_map(content_transformer(replace_abbreviation)) %>%
  tm_map(content_transformer(replace_contraction)) %>%
  tm_map(content_transformer(str_to_lower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords("en")) %>%
  tm_map(removeWords, c(io_stem, psych_stem, "iopsychology", "riopsychology")) %>%
  tm_map(stripWhitespace) %>%
  tm_map(content_transformer(lemmatize_strings))

compare_them <- function(corpus_1, corpus_2){
  sample_num <- sample(nrow(week12_tbl), 1)
  compare <- list(corpus_1[[sample_num]]$content, corpus_2[[sample_num]]$content)
  return(compare)
}

compare_them(io_corpus, io_corpus_original)

bi_token <- function(x){
  NGramTokenizer(x, Weka_control(min = 1, max = 2))
}

io_dtm <- DocumentTermMatrix(
  io_corpus, 
  control = list(tokenizer = bi_token)
)

io_slim_dtm <- removeSparseTerms(io_dtm, 0.996)

tokenCounts <- apply(io_slim_dtm, 1, sum)
io_slim_dtm_complete <- io_slim_dtm[tokenCounts > 0, ]
```

### Analysis
```{r}
cluster <- makeCluster(7)
registerDoParallel(cluster)

io_tuning <- FindTopicsNumber(
  io_slim_dtm_complete,
  topics = seq(3,15,3),
  metrics = c("Griffiths2004",
              "CaoJuan2009",
              "Arun2010",
              "Deveaud2014"),
  verbose = T
)

FindTopicsNumber_plot(io_tuning)

stopCluster(cluster)
registerDoSEQ()

lda_results <- LDA(io_slim_dtm_complete, 9)

lda_betas <- tidy(lda_results, matrix = "beta")
lda_gammas <- tidy(lda_results, matrix = "gamma")

lda_betas %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  arrange(topic) %>%
  view()

lda_gammas_selected <- lda_gammas %>%
  group_by(document) %>%
  top_n(1, gamma) %>%
  slice(1) %>%
  ungroup %>%
  mutate(doc_id = as.numeric(document),
         probability = gamma) %>%
  arrange(document) %>%
  select(-document, -gamma)

doc_id <- c(1:nrow(week12_tbl))
original <- week12_tbl$title

doc_title_tibble <- tibble(doc_id, original)

topics_tbl <- doc_title_tibble %>%
  left_join(lda_gammas_selected, by = "doc_id")

# Using the beta matrix alone, what topics would you conclude your final topic list maps onto?
## Topic 1 seems to be about research and analysis
## Topic 2 seems to be about learning and education
## Topic 3 seems to be about reading and discussion 
## Topic 4 seems to be about job advice 
## Topic 5 seems to be about practical recommendations 
## Topic 6 seems to be about career choices for phd and master students
## Topic 7 seems to be about siop conference
## Topic 8 seems to be about advice for working in people analytics
## Topic 9 seems to be about general questions about graduate school, research, and work 

# Look at the original text of documents with the highest and lowest probabilities assigned to each document. Do your topic names derived from your interpretation of the beta matrix conceptually match with the content of the original posts? What kind of validity evidence does your answer to this question represent?

## Overall speaking, I think the post content matches pretty well with my topic names. For example, all the weekly discussion posts were categorized under Topic 3, which I named as reading and discussion. Take another example, post 88, which asked for thoughts on the use of personality tests for selection, had the highest probability for Topic 5, which I summarized as practical recommendations. However, there are also some posts that did not fit into the general topic, such as post 802, which was about executive coaching career advice, yet it had the highest probability for Topic 7, which I named as siop conference. 
## And the answer to this question would provide evidence for content validity. 


slim_dtm_df <- as_tibble(as.matrix(io_slim_dtm))

wordcounts <- colSums(slim_dtm_df)
wordnames <- names(slim_dtm_df)

wordcloud(wordnames, wordcounts, max.words = 50, scale = c(2, .5))

##Looking at the wordcloud generated from the post data, it seems that work, research, and career appeared most frequently in all the posts. Moreover, there are many words that are related to asking for advice (e.g., question, help, advice), suggesting that people like to ask questions and seek advice about career choices and io-related research on the IO Psychology subreddit. 

week12_tbl_num <- week12_tbl %>%
  mutate(doc_id = as.numeric(1:nrow(week12_tbl)))

final_tbl <- topics_tbl %>%
  left_join(week12_tbl_num, by = "doc_id")

oneway.test(upvotes ~ topic, data = final_tbl)

# The one-way ANOVA test indicates a significant effect of topic on the number of upvotes (p < 0.05), thus suggesting that the number of upvotes does differ by topic. 
```




